model: all-distilroberta-v1-text-concatenation
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.0001}
validation accuracy: 0.9552
test accuracy: 0.9628
macro precision: 0.9575
macro recall: 0.9086
macro f1-score: 0.9308
weighted precision: 0.9625
weighted recall: 0.9628
weighted f1-score: 0.9618
--------------------------------------------------
model: all-distilroberta-v1-vector-sum
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001}
validation accuracy: 0.9515
test accuracy: 0.9851
macro precision: 0.9738
macro recall: 0.9738
macro f1-score: 0.9738
weighted precision: 0.9851
weighted recall: 0.9851
weighted f1-score: 0.9851
--------------------------------------------------
model: all-distilroberta-v1-vector-concatenation
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9590
test accuracy: 0.9888
macro precision: 0.9844
macro recall: 0.9760
macro f1-score: 0.9802
weighted precision: 0.9888
weighted recall: 0.9888
weighted f1-score: 0.9888
--------------------------------------------------
model: all-distilroberta-v1-vector-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001}
validation accuracy: 0.9515
test accuracy: 0.9851
macro precision: 0.9738
macro recall: 0.9738
macro f1-score: 0.9738
weighted precision: 0.9851
weighted recall: 0.9851
weighted f1-score: 0.9851
--------------------------------------------------
model: all-distilroberta-v1-vector-weighted-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001}
validation accuracy: 0.9552
test accuracy: 0.9740
macro precision: 0.9577
macro recall: 0.9498
macro f1-score: 0.9537
weighted precision: 0.9738
weighted recall: 0.9740
weighted f1-score: 0.9739
--------------------------------------------------
model: all-mpnet-base-v2-text-concatenation
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.01}
validation accuracy: 0.9590
test accuracy: 0.9777
macro precision: 0.9538
macro recall: 0.9693
macro f1-score: 0.9613
weighted precision: 0.9782
weighted recall: 0.9777
weighted f1-score: 0.9779
--------------------------------------------------
model: all-mpnet-base-v2-vector-sum
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9590
test accuracy: 0.9740
macro precision: 0.9444
macro recall: 0.9671
macro f1-score: 0.9553
weighted precision: 0.9750
weighted recall: 0.9740
weighted f1-score: 0.9743
--------------------------------------------------
model: all-mpnet-base-v2-vector-concatenation
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.9664
test accuracy: 0.9665
macro precision: 0.9268
macro recall: 0.9626
macro f1-score: 0.9434
weighted precision: 0.9689
weighted recall: 0.9665
weighted f1-score: 0.9672
--------------------------------------------------
model: all-mpnet-base-v2-vector-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9590
test accuracy: 0.9740
macro precision: 0.9444
macro recall: 0.9671
macro f1-score: 0.9553
weighted precision: 0.9750
weighted recall: 0.9740
weighted f1-score: 0.9743
--------------------------------------------------
model: all-mpnet-base-v2-vector-weighted-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9701
test accuracy: 0.9777
macro precision: 0.9477
macro recall: 0.9779
macro f1-score: 0.9620
weighted precision: 0.9791
weighted recall: 0.9777
weighted f1-score: 0.9781
--------------------------------------------------
model: all-MiniLM-L6-v2-text-concatenation
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9552
test accuracy: 0.9517
macro precision: 0.9070
macro recall: 0.9277
macro f1-score: 0.9169
weighted precision: 0.9532
weighted recall: 0.9517
weighted f1-score: 0.9523
--------------------------------------------------
model: all-MiniLM-L6-v2-vector-sum
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.0001}
validation accuracy: 0.9627
test accuracy: 0.9740
macro precision: 0.9577
macro recall: 0.9498
macro f1-score: 0.9537
weighted precision: 0.9738
weighted recall: 0.9740
weighted f1-score: 0.9739
--------------------------------------------------
model: all-MiniLM-L6-v2-vector-concatenation
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9664
test accuracy: 0.9628
macro precision: 0.9285
macro recall: 0.9431
macro f1-score: 0.9355
weighted precision: 0.9636
weighted recall: 0.9628
weighted f1-score: 0.9631
--------------------------------------------------
model: all-MiniLM-L6-v2-vector-average
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.0001}
validation accuracy: 0.9627
test accuracy: 0.9740
macro precision: 0.9577
macro recall: 0.9498
macro f1-score: 0.9537
weighted precision: 0.9738
weighted recall: 0.9740
weighted f1-score: 0.9739
--------------------------------------------------
model: all-MiniLM-L6-v2-vector-weighted-average
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9627
test accuracy: 0.9703
macro precision: 0.9548
macro recall: 0.9389
macro f1-score: 0.9466
weighted precision: 0.9699
weighted recall: 0.9703
weighted f1-score: 0.9700
--------------------------------------------------
model: S-PubMedBert-MS-MARCO-text-concatenation
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9590
test accuracy: 0.9628
macro precision: 0.9285
macro recall: 0.9431
macro f1-score: 0.9355
weighted precision: 0.9636
weighted recall: 0.9628
weighted f1-score: 0.9631
--------------------------------------------------
model: S-PubMedBert-MS-MARCO-vector-sum
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9701
test accuracy: 0.9703
macro precision: 0.9354
macro recall: 0.9648
macro f1-score: 0.9493
weighted precision: 0.9719
weighted recall: 0.9703
weighted f1-score: 0.9707
--------------------------------------------------
model: S-PubMedBert-MS-MARCO-vector-concatenation
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9664
test accuracy: 0.9777
macro precision: 0.9538
macro recall: 0.9693
macro f1-score: 0.9613
weighted precision: 0.9782
weighted recall: 0.9777
weighted f1-score: 0.9779
--------------------------------------------------
model: S-PubMedBert-MS-MARCO-vector-average
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9701
test accuracy: 0.9703
macro precision: 0.9354
macro recall: 0.9648
macro f1-score: 0.9493
weighted precision: 0.9719
weighted recall: 0.9703
weighted f1-score: 0.9707
--------------------------------------------------
model: S-PubMedBert-MS-MARCO-vector-weighted-average
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9664
test accuracy: 0.9740
macro precision: 0.9444
macro recall: 0.9671
macro f1-score: 0.9553
weighted precision: 0.9750
weighted recall: 0.9740
weighted f1-score: 0.9743
--------------------------------------------------
model: pubmedbert-base-embeddings-text-concatenation
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9701
test accuracy: 0.9777
macro precision: 0.9477
macro recall: 0.9779
macro f1-score: 0.9620
weighted precision: 0.9791
weighted recall: 0.9777
weighted f1-score: 0.9781
--------------------------------------------------
model: pubmedbert-base-embeddings-vector-sum
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9664
test accuracy: 0.9740
macro precision: 0.9340
macro recall: 0.9843
macro f1-score: 0.9567
weighted precision: 0.9774
weighted recall: 0.9740
weighted f1-score: 0.9747
--------------------------------------------------
model: pubmedbert-base-embeddings-vector-concatenation
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001}
validation accuracy: 0.9664
test accuracy: 0.9703
macro precision: 0.9259
macro recall: 0.9821
macro f1-score: 0.9509
weighted precision: 0.9747
weighted recall: 0.9703
weighted f1-score: 0.9712
--------------------------------------------------
model: pubmedbert-base-embeddings-vector-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9664
test accuracy: 0.9740
macro precision: 0.9340
macro recall: 0.9843
macro f1-score: 0.9567
weighted precision: 0.9774
weighted recall: 0.9740
weighted f1-score: 0.9747
--------------------------------------------------
model: pubmedbert-base-embeddings-vector-weighted-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9701
test accuracy: 0.9740
macro precision: 0.9389
macro recall: 0.9757
macro f1-score: 0.9560
weighted precision: 0.9761
weighted recall: 0.9740
weighted f1-score: 0.9745
--------------------------------------------------
model: bert-base-uncased-mask-text-concatenation
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.8806
test accuracy: 0.8848
macro precision: 0.8123
macro recall: 0.7493
macro f1-score: 0.7747
weighted precision: 0.8767
weighted recall: 0.8848
weighted f1-score: 0.8783
--------------------------------------------------
model: bert-base-uncased-mask-vector-sum
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9142
test accuracy: 0.9331
macro precision: 0.8988
macro recall: 0.8561
macro f1-score: 0.8754
weighted precision: 0.9309
weighted recall: 0.9331
weighted f1-score: 0.9312
--------------------------------------------------
model: bert-base-uncased-mask-vector-concatenation
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.0001}
validation accuracy: 0.9104
test accuracy: 0.9294
macro precision: 0.8777
macro recall: 0.8711
macro f1-score: 0.8744
weighted precision: 0.9288
weighted recall: 0.9294
weighted f1-score: 0.9291
--------------------------------------------------
model: bert-base-uncased-mask-vector-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.9142
test accuracy: 0.9331
macro precision: 0.8988
macro recall: 0.8561
macro f1-score: 0.8754
weighted precision: 0.9309
weighted recall: 0.9331
weighted f1-score: 0.9312
--------------------------------------------------
model: bert-base-uncased-mask-vector-weighted-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001}
validation accuracy: 0.9104
test accuracy: 0.8922
macro precision: 0.8239
macro recall: 0.7711
macro f1-score: 0.7934
weighted precision: 0.8859
weighted recall: 0.8922
weighted f1-score: 0.8874
--------------------------------------------------
model: bert-base-uncased-raw-text-concatenation
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.0001}
validation accuracy: 0.9328
test accuracy: 0.9219
macro precision: 0.8798
macro recall: 0.8321
macro f1-score: 0.8533
weighted precision: 0.9188
weighted recall: 0.9219
weighted f1-score: 0.9193
--------------------------------------------------
model: bert-base-uncased-raw-vector-sum
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9366
test accuracy: 0.9554
macro precision: 0.9276
macro recall: 0.9127
macro f1-score: 0.9199
weighted precision: 0.9548
weighted recall: 0.9554
weighted f1-score: 0.9550
--------------------------------------------------
model: bert-base-uncased-raw-vector-concatenation
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9366
test accuracy: 0.9591
macro precision: 0.9459
macro recall: 0.9063
macro f1-score: 0.9246
weighted precision: 0.9584
weighted recall: 0.9591
weighted f1-score: 0.9582
--------------------------------------------------
model: bert-base-uncased-raw-vector-average
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.9366
test accuracy: 0.9554
macro precision: 0.9276
macro recall: 0.9127
macro f1-score: 0.9199
weighted precision: 0.9548
weighted recall: 0.9554
weighted f1-score: 0.9550
--------------------------------------------------
model: bert-base-uncased-raw-vector-weighted-average
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001}
validation accuracy: 0.9216
test accuracy: 0.9442
macro precision: 0.9103
macro recall: 0.8887
macro f1-score: 0.8990
weighted precision: 0.9431
weighted recall: 0.9442
weighted f1-score: 0.9435
--------------------------------------------------
model: bigbird-roberta-large-mask-text-concatenation
params: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.0001}
validation accuracy: 0.8396
test accuracy: 0.8327
macro precision: 0.7186
macro recall: 0.5281
macro f1-score: 0.5126
weighted precision: 0.7966
weighted recall: 0.8327
weighted f1-score: 0.7725
--------------------------------------------------
model: bigbird-roberta-large-mask-vector-sum
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.8284
test accuracy: 0.8290
macro precision: 0.4145
macro recall: 0.5000
macro f1-score: 0.4533
weighted precision: 0.6872
weighted recall: 0.8290
weighted f1-score: 0.7515
--------------------------------------------------
model: bigbird-roberta-large-mask-vector-concatenation
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.001}
validation accuracy: 0.8246
test accuracy: 0.8290
macro precision: 0.4145
macro recall: 0.5000
macro f1-score: 0.4533
weighted precision: 0.6872
weighted recall: 0.8290
weighted f1-score: 0.7515
--------------------------------------------------
model: bigbird-roberta-large-mask-vector-average
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.8284
test accuracy: 0.8290
macro precision: 0.4145
macro recall: 0.5000
macro f1-score: 0.4533
weighted precision: 0.6872
weighted recall: 0.8290
weighted f1-score: 0.7515
--------------------------------------------------
model: bigbird-roberta-large-mask-vector-weighted-average
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.8284
test accuracy: 0.8290
macro precision: 0.4145
macro recall: 0.5000
macro f1-score: 0.4533
weighted precision: 0.6872
weighted recall: 0.8290
weighted f1-score: 0.7515
--------------------------------------------------
model: bigbird-roberta-large-raw-text-concatenation
params: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.9291
test accuracy: 0.9294
macro precision: 0.8733
macro recall: 0.8798
macro f1-score: 0.8765
weighted precision: 0.9300
weighted recall: 0.9294
weighted f1-score: 0.9297
--------------------------------------------------
model: bigbird-roberta-large-raw-vector-sum
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.9216
test accuracy: 0.9182
macro precision: 0.8694
macro recall: 0.8299
macro f1-score: 0.8478
weighted precision: 0.9151
weighted recall: 0.9182
weighted f1-score: 0.9159
--------------------------------------------------
model: bigbird-roberta-large-raw-vector-concatenation
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.9328
test accuracy: 0.9257
macro precision: 0.9071
macro recall: 0.8171
macro f1-score: 0.8532
weighted precision: 0.9234
weighted recall: 0.9257
weighted f1-score: 0.9210
--------------------------------------------------
model: bigbird-roberta-large-raw-vector-average
params: {'hidden_layer_sizes': (512, 256, 128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.9216
test accuracy: 0.9182
macro precision: 0.8694
macro recall: 0.8299
macro f1-score: 0.8478
weighted precision: 0.9151
weighted recall: 0.9182
weighted f1-score: 0.9159
--------------------------------------------------
model: bigbird-roberta-large-raw-vector-weighted-average
params: {'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.01}
validation accuracy: 0.9216
test accuracy: 0.9517
macro precision: 0.9315
macro recall: 0.8932
macro f1-score: 0.9109
weighted precision: 0.9506
weighted recall: 0.9517
weighted f1-score: 0.9506
--------------------------------------------------
